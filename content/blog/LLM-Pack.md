---
title: "LLM (LANGCHAIN GEN AI) PACK"
description: "Created an LANGCHAIN GEN AI PACK which is deployed on CELLSTRAT Hub"
dateString: Jan 2024
draft: false
tags: ["LLM", "GEN AI", "LLM Blog"]
weight: 101
cover:
    image: "/blog/LLM-Pack/LLM.png"
---

<!-- # Credentials
### ðŸ”— [Certificate](https://drive.google.com/file/d/1VhFPfb1cc7ORFVqFetCvpiGLPE96ofg4/view?usp=sharing)

### ðŸ”— [Credly Badge](https://www.credly.com/badges/b08022fe-627a-4b78-8647-b42955f50767/public_url)

### ðŸŽ¬ [YouTube Video](https://youtu.be/x88k9fuEDuE) -->

# Introduction
I've developed an LLM(GEN AI) PACK which is deployed on [CELLSTRAT Hub](https://console.cellstrathub.com/packs/langchain-gen-ai). This pack contains a series of projects developed as part of the LangChain initiative, demonstrating various applications and use cases leveraging language models and generative AI. Each project is designed to showcase the capabilities of different technologies and platforms.

## Table Of Contents

Here's a brief description for each item in the table of contents:

1. **LLM1-Basics of LLM**: This section covers the fundamentals of LLM (Large Language Models), providing an introduction to its concepts, applications, and underlying technologies.

2. **LLM2-Querying PDF with AstraDB**: In this section, you'll learn about querying PDF documents using AstraDB, exploring techniques and methods for efficiently retrieving information from PDF files.

3. **LLM3-Blog Generation using LLAMA 2**: This section delves into the process of generating blog content using LLAMA 2, an advanced language model tailored for content creation tasks.

4. **LLM4-LLM Generic App using Pinecone VectorDB**: Here, you'll discover how to build a generic application using LLM, leveraging Pinecone VectorDB for managing and querying large-scale vector data efficiently.

5. **LLM5-Gemini Pro LLM Application**: This section focuses on the Gemini Pro LLM Application, showcasing its features, capabilities, and practical applications in various domains.

6. **LLM6-Invoice Extractor using Gemini Pro Vision**: In this section, you'll explore the development and implementation of an invoice extractor using Gemini Pro Vision, a vision-based application powered by LLM technology.

![Image Alt Text](/blog/LLM-Pack/Expansion.png)



# What is CELLSTRAT Hub ?
**CellStrat Hub** is a full-stack AI skilling, development and deployment platform. It enables students and learners to upskill in various domains of AI as well as develop AI projects easily and efficiently. CellStrat Hub's core value is to make AI simpler for everyone. CellStrat Hub includes a wide range of features for development, learning and deployment.
![Image Alt Text](/blog/LLM-Pack/CellStart.png)



## Workspace
CellStrat Hub **Workspace** is a simple yet powerful fully-managed development environment for rapid AI development based on JupyterLab. Workspace comes with a whole suite of features like,

A Dedicated Virtual Machine on the Cloud with Jupyter Lab
Persistent Storage for all your Files
One-Click Realtime Collaborative Coding (think Google Docs for Code)
Visual Debugger to easily debug your swamps of code
Code-Snippets Extension to save your frequently used snippets of code and reuse them in any of your projects with the click of a button
Seamless Git Integration via both, SSH (recommended) and Personal Access Token
A Curated Set of Project Packs with Code Repositories in all major fields of AI like Computer Vision, Natural Language Processing, Reinforcement Learning and Much More.

![](/blog/LLM-Pack/Workspace.png)

## Expansion Packs
Getting Started with practical machine learning as a beginner is a tedious task with so many projects and options spread all across the internet. Its very easy to get lost in the sea of resources that are out there. To solve this issue, Hub comes with Expansion Packs that are a curated list of projects to get you started in a particular field of AI. If you are a beginner, these packs will help you get hands-on experience and practice. If you are an expert already, these packs will help you jumpstart your project so you can build on top of it.

![](/blog/LLM-Pack/EPack.png)
